{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918a9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing author: Vivek Muthurangu\n",
      "Processing author: Jennifer Steeden\n",
      "Processing author: Daniel Knight\n",
      "Processing author: Michael Quail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322900/2569408491.py:156: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[df['Affiliations'].astype(str).str.contains(affil_pattern, na=False)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch_pubmed_ids(author, retmax=200):\n",
    "    url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': f'{author}[Author]',\n",
    "        'retmax': retmax,\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    root = ET.fromstring(response.content)\n",
    "    ids = [id_elem.text for id_elem in root.findall('./IdList/Id')]\n",
    "    return ids\n",
    "\n",
    "def fetch_pubmed_records(id_list):\n",
    "    url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "    if not id_list:\n",
    "        return b''  # return empty bytes if no IDs\n",
    "    ids = ','.join(id_list)\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': ids,\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.content\n",
    "\n",
    "def parse_pubmed_xml(xml_data):\n",
    "    if not xml_data:\n",
    "        return []\n",
    "    root = ET.fromstring(xml_data)\n",
    "    records = []\n",
    "    for article in root.findall('.//PubmedArticle'):\n",
    "        try:\n",
    "            article_title = article.findtext('.//ArticleTitle')\n",
    "            journal = article.findtext('.//Journal/Title')\n",
    "\n",
    "            if len(article_title) < 4:\n",
    "                article_title = pd.NA  # you used np.nan, but pandas NA is cleaner in newer versions\n",
    "\n",
    "            authors = []\n",
    "            affiliations = set()\n",
    "\n",
    "            for author in article.findall('.//AuthorList/Author'):\n",
    "                last = author.findtext('LastName')\n",
    "                fore = author.findtext('ForeName')\n",
    "                if last and fore:\n",
    "                    authors.append(f\"{last} {fore[0]}.\")\n",
    "                elif last:\n",
    "                    authors.append(last)\n",
    "\n",
    "                # Affiliation (can be multiple)\n",
    "                aff_list = author.findall('.//AffiliationInfo/Affiliation')\n",
    "                for aff in aff_list:\n",
    "                    if aff is not None and aff.text:\n",
    "                        affiliations.add(aff.text.strip())\n",
    "\n",
    "            authors = ', '.join(authors)\n",
    "            affiliation_str = '; '.join(affiliations) if affiliations else None\n",
    "\n",
    "            pub_date_elem = article.find('.//Journal/JournalIssue/PubDate')\n",
    "            pub_date_str = None\n",
    "            year = None\n",
    "            if pub_date_elem is not None:\n",
    "                year = pub_date_elem.findtext('Year')\n",
    "                medline_date = pub_date_elem.findtext('MedlineDate')\n",
    "                month = pub_date_elem.findtext('Month')\n",
    "                day = pub_date_elem.findtext('Day')\n",
    "                if year:\n",
    "                    pub_date_str = year\n",
    "                    if month:\n",
    "                        pub_date_str += f\"-{month}\"\n",
    "                    if day:\n",
    "                        pub_date_str += f\"-{day}\"\n",
    "                elif medline_date:\n",
    "                    pub_date_str = medline_date\n",
    "\n",
    "            doi = None\n",
    "            for article_id in article.findall('.//ArticleIdList/ArticleId'):\n",
    "                if article_id.attrib.get('IdType') == 'doi':\n",
    "                    doi = article_id.text\n",
    "                    break\n",
    "\n",
    "            records.append({\n",
    "                'Title': article_title,\n",
    "                'Journal': journal,\n",
    "                'Authors': authors,\n",
    "                'Affiliations': affiliation_str,\n",
    "                'Year': year,\n",
    "                'DOI': doi,\n",
    "                'DocumentType': 'Article',\n",
    "                'PublicationDate': pub_date_str\n",
    "            })\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Convert PublicationDate strings to pandas datetime, coercing errors\n",
    "    for r in records:\n",
    "        date_str = r['PublicationDate']\n",
    "        if date_str:\n",
    "            r['PublicationDate'] = pd.to_datetime(date_str, errors='coerce')\n",
    "        else:\n",
    "            r['PublicationDate'] = pd.NaT\n",
    "    return records\n",
    "\n",
    "\n",
    "\n",
    "# List of authors to process\n",
    "authors_list = [\n",
    "    \"Vivek Muthurangu\",\n",
    "    \"Jennifer Steeden\",\n",
    "    \"Daniel Knight\",\n",
    "    \"Michael Quail\"\n",
    "]\n",
    "\n",
    "# all_authors = [\n",
    "#     \"Yao\",\n",
    "#     \"Muthurangu\",\n",
    "#     \"Steeden\",\n",
    "#     \"Knight\",\n",
    "#     'Quail',\n",
    "#     'Jiang',\n",
    "#     'Yong',\n",
    "#     'Wrobel',\n",
    "#     'Pascale',\n",
    "#     'Montalt',\n",
    "#     'Jaubert',\n",
    "#     'Baker',\n",
    "#     'Raman',\n",
    "#     'Campbell'\n",
    "# ]\n",
    "\n",
    "all_records = []\n",
    "\n",
    "for author in authors_list:\n",
    "    print(f\"Processing author: {author}\")\n",
    "    ids = fetch_pubmed_ids(author, retmax=200)\n",
    "    xml_data = fetch_pubmed_records(ids)\n",
    "    records = parse_pubmed_xml(xml_data)\n",
    "    all_records.extend(records)\n",
    "    time.sleep(0.5)  # polite pause to avoid hitting API limits\n",
    "\n",
    "# Convert all records to a DataFrame\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(all_records).drop_duplicates('Title').sort_values('PublicationDate', ascending=False)\n",
    "# Define regex pattern for affiliation filtering\n",
    "affil_pattern = r'(?i)\\b(UCL|University College London|Great Ormond Street)\\b'\n",
    "\n",
    "# Keep only rows with matching affiliations\n",
    "df = df[df['Affiliations'].astype(str).str.contains(affil_pattern, na=False)]\n",
    "\n",
    "df.to_json('data/pubs.json', orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81baf64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
